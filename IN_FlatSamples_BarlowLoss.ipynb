{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aeefce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports basics\n",
    "import numpy as np\n",
    "import h5py\n",
    "import json\n",
    "import setGPU\n",
    "import sklearn\n",
    "import corner\n",
    "import os\n",
    "import scipy\n",
    "# Imports neural net tools\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd.variable import *\n",
    "import torch.optim as optim\n",
    "from fast_soft_sort.pytorch_ops import soft_rank\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dbf55b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting\n",
      "(3074667, 207)\n"
     ]
    }
   ],
   "source": [
    "# Opens files and reads data\n",
    "\n",
    "print(\"Extracting\")\n",
    "n_encoded_nodes = 8\n",
    "weightClr = 1\n",
    "weightCorr1 = 10\n",
    "weightCorr2 = 5\n",
    "loss_text=\"%iD encoder, $\\lambda_{CLR}$=%i, $\\lambda_{corr1}$=%i, $\\lambda_{corr2}$=%i\"%(n_encoded_nodes, weightClr, weightCorr1, weightCorr2)\n",
    "\n",
    "label=f'contrastiveBarlow_{n_encoded_nodes}_dimensions_{weightClr}Clr_{weightCorr1}Corr1_{weightCorr2}Corr2'\n",
    "outdir = '/uscms_data/d3/jkrupa/flat/FlatSamples/plots/'+label\n",
    "os.system(f'mkdir -p {outdir}')\n",
    "fOne = h5py.File(\"/uscms_data/d3/eamoreno/FlatSamples/data/FullQCD_FullSig_Zqq_noFill_dRlimit08_50particlesordered_genMatched50.h5\", 'r')\n",
    "totalData = fOne[\"deepDoubleQ\"][:]\n",
    "print(totalData.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "378cd508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets controllable values\n",
    "\n",
    "particlesConsidered = 50\n",
    "particlesPostCut = 50\n",
    "entriesPerParticle = 4\n",
    "eventDataLength = 6\n",
    "decayTypeColumn = -1\n",
    "datapoints = 1400000\n",
    "#datapoints = len(totalData)\n",
    "trainingDataLength = int(len(totalData)*0.8)\n",
    "validationDataLength = int(len(totalData)*0.1)\n",
    "modelName = \"IN_FlatSamples_EighthQCDEighthSig_50particles_pTsdmassfilling_dRlimit08\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "685318e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Data\n",
      "[[-0.8218427  -0.9793822   0.82931083 ...  0.          0.\n",
      "   0.        ]\n",
      " [-1.9116873  -1.3553605   0.22445557 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.20539148  1.5885682   0.19883753 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 2.1065607   1.7468735   0.6948912  ...  0.          0.\n",
      "   1.        ]\n",
      " [ 1.0260688  -2.8028588   0.21128003 ...  1.          1.\n",
      "   1.        ]\n",
      " [ 1.3903469   2.9405048   3.047642   ... -1.         -1.\n",
      "   1.        ]]\n",
      "Selecting particlesPostCut\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creates Training Data\n",
    "\n",
    "print(\"Preparing Data\")\n",
    "\n",
    "particleDataLength = particlesConsidered * entriesPerParticle\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(totalData)\n",
    "\n",
    "#trainingDataLength = int(datapoints*0.8)\n",
    "#validationDataLength = int(datapoints*0.1)\n",
    "\n",
    "mask = [i>40 for i in totalData[:, eventDataLength-1]]\n",
    "totalData = totalData[mask]\n",
    "print(totalData)\n",
    "labels = totalData[:, decayTypeColumn:]\n",
    "particleData = totalData[:, eventDataLength:particleDataLength + eventDataLength]\n",
    "eventData = totalData[:, :eventDataLength]\n",
    "jetMassData = totalData[:, eventDataLength-1] #last entry in eventData (zero indexing)\n",
    "\n",
    "\n",
    "######### Training Data ###############\n",
    "eventTrainingData = np.array(eventData[0:trainingDataLength],dtype=np.float16)\n",
    "jetMassTrainingData = np.array(jetMassData[0:trainingDataLength],dtype=np.float16)\n",
    "particleTrainingData = np.transpose(\n",
    "    particleData[0:trainingDataLength, ].reshape(trainingDataLength, \n",
    "                                                 entriesPerParticle, \n",
    "                                                 particlesConsidered),\n",
    "                                                 axes=(0, 1, 2))\n",
    "particleTrainingData = particleTrainingData.astype(np.float16)\n",
    "\n",
    "trainingLabels = np.array([[i, 1-i] for i in labels[0:trainingDataLength]]).reshape((-1, 2))\n",
    "\n",
    "torch.save(torch.Tensor(particleTrainingData),f\"{outdir}/{label}_particleTrainingData.pt\")\n",
    "torch.save(torch.Tensor(jetMassTrainingData),f\"{outdir}/{label}_jetMassTrainingData.pt\")\n",
    "torch.save(torch.Tensor(trainingLabels),f\"{outdir}/{label}_trainingLabels.pt\")\n",
    "\n",
    "\n",
    "########## Validation Data ##########\n",
    "eventValidationData = np.array(eventData[trainingDataLength:trainingDataLength + validationDataLength])\n",
    "jetMassValidationData = np.array(jetMassData[trainingDataLength:trainingDataLength + validationDataLength])\n",
    "particleValidationData = np.transpose(\n",
    "    particleData[trainingDataLength:trainingDataLength + validationDataLength, ].reshape(validationDataLength,\n",
    "                                                                                         entriesPerParticle,\n",
    "                                                                                         particlesConsidered),\n",
    "                                                                                         axes=(0, 1, 2))\n",
    "validationLabels = np.array([[i, 1-i] for i in labels[trainingDataLength:trainingDataLength + validationDataLength]]).reshape((-1, 2))\n",
    "\n",
    "\n",
    "\n",
    "########### Testing Data ############\n",
    "particleTestData = np.transpose(particleData[trainingDataLength + validationDataLength:,].reshape(\n",
    "    len(particleData) - trainingDataLength - validationDataLength, entriesPerParticle, particlesConsidered),\n",
    "                                axes=(0, 1, 2))\n",
    "testLabels = np.array(labels[trainingDataLength + validationDataLength:])\n",
    "\n",
    "print('Selecting particlesPostCut')\n",
    "particleTrainingData = particleTrainingData[:, :particlesPostCut]\n",
    "particleValidationData = particleValidationData[:, :particlesPostCut]\n",
    "\n",
    "particlesConsidered = particlesPostCut\n",
    "\n",
    "# Separating signal and bkg arrays\n",
    "particleTrainingDataSig = particleTrainingData[trainingLabels[:,0].astype(bool)]\n",
    "particleTrainingDataBkg = particleTrainingData[trainingLabels[:,1].astype(bool)]\n",
    "particleValidationDataSig = particleValidationData[validationLabels[:,0].astype(bool)]\n",
    "particleValidationDataBkg = particleValidationData[validationLabels[:,1].astype(bool)]\n",
    "particleTrainingLabelSig = trainingLabels[trainingLabels[:,0].astype(bool)]\n",
    "particleTrainingLabelBkg = trainingLabels[trainingLabels[:,1].astype(bool)]\n",
    "\n",
    "# Jet mass for correlation\n",
    "jetMassTrainingDataSig = jetMassTrainingData[trainingLabels[:,0].astype(bool)]\n",
    "jetMassTrainingDataBkg = jetMassTrainingData[trainingLabels[:,1].astype(bool)]\n",
    "jetMassValidationDataSig = jetMassValidationData[validationLabels[:,0].astype(bool)]\n",
    "jetMassValidationDataBkg = jetMassValidationData[validationLabels[:,1].astype(bool)]\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.hist(jetMassTrainingDataSig,color=\"r\",bins=20,alpha=0.5,label=\"Z'\")\n",
    "ax.hist(jetMassTrainingDataBkg,color=\"b\",bins=20,alpha=0.5,label=\"QCD\")\n",
    "plt.legend(loc=\"best\")\n",
    "ax.set_xlabel(\"Jet mass (GeV))\")\n",
    "ax.set_ylabel(\"Counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4103a733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the interaction matrices\n",
    "class GraphNetnoSV(nn.Module):\n",
    "    def __init__(self, n_constituents, n_targets, params, hidden, De=5, Do=6, softmax=False):\n",
    "        super(GraphNetnoSV, self).__init__()\n",
    "        self.hidden = int(hidden)\n",
    "        self.P = params\n",
    "        self.Nv = 0 \n",
    "        self.N = n_constituents\n",
    "        self.Nr = self.N * (self.N - 1)\n",
    "        self.Nt = self.N * self.Nv\n",
    "        self.Ns = self.Nv * (self.Nv - 1)\n",
    "        self.Dr = 0\n",
    "        self.De = De\n",
    "        self.Dx = 0\n",
    "        self.Do = Do\n",
    "        self.S = 0\n",
    "        self.n_targets = n_targets\n",
    "        self.assign_matrices()\n",
    "           \n",
    "        self.Ra = torch.ones(self.Dr, self.Nr)\n",
    "        self.fr1 = nn.Linear(2 * self.P + self.Dr, self.hidden).cuda()\n",
    "        self.fr2 = nn.Linear(self.hidden, int(self.hidden/2)).cuda()\n",
    "        self.fr3 = nn.Linear(int(self.hidden/2), self.De).cuda()\n",
    "        self.fr1_pv = nn.Linear(self.S + self.P + self.Dr, self.hidden).cuda()\n",
    "        self.fr2_pv = nn.Linear(self.hidden, int(self.hidden/2)).cuda()\n",
    "        self.fr3_pv = nn.Linear(int(self.hidden/2), self.De).cuda()\n",
    "        \n",
    "        self.fo1 = nn.Linear(self.P + self.Dx + (self.De), self.hidden).cuda()\n",
    "        self.fo2 = nn.Linear(self.hidden, int(self.hidden/2)).cuda()\n",
    "        self.fo3 = nn.Linear(int(self.hidden/2), self.Do).cuda()\n",
    "        \n",
    "        self.fc_fixed = nn.Linear(self.Do, self.n_targets).cuda()\n",
    "        self.activation = torch.nn.Sigmoid()\n",
    "            \n",
    "    def assign_matrices(self):\n",
    "        self.Rr = torch.zeros(self.N, self.Nr)\n",
    "        self.Rs = torch.zeros(self.N, self.Nr)\n",
    "        receiver_sender_list = [i for i in itertools.product(range(self.N), range(self.N)) if i[0]!=i[1]]\n",
    "        for i, (r, s) in enumerate(receiver_sender_list):\n",
    "            self.Rr[r, i] = 1\n",
    "            self.Rs[s, i] = 1\n",
    "        self.Rr = (self.Rr).cuda()\n",
    "        self.Rs = (self.Rs).cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        ###PF Candidate - PF Candidate###\n",
    "        Orr = self.tmul(x, self.Rr)\n",
    "        Ors = self.tmul(x, self.Rs)\n",
    "        B = torch.cat([Orr, Ors], 1)\n",
    "        ### First MLP ###\n",
    "        B = torch.transpose(B, 1, 2).contiguous()\n",
    "        B = nn.functional.relu(self.fr1(B.view(-1, 2 * self.P + self.Dr)))\n",
    "        B = nn.functional.relu(self.fr2(B))\n",
    "        E = nn.functional.relu(self.fr3(B).view(-1, self.Nr, self.De))\n",
    "        del B\n",
    "        E = torch.transpose(E, 1, 2).contiguous()\n",
    "        Ebar_pp = self.tmul(E, torch.transpose(self.Rr, 0, 1).contiguous())\n",
    "        del E\n",
    "        \n",
    "\n",
    "        ####Final output matrix for particles###\n",
    "        \n",
    "\n",
    "        C = torch.cat([x, Ebar_pp], 1)\n",
    "        del Ebar_pp\n",
    "        C = torch.transpose(C, 1, 2).contiguous()\n",
    "        ### Second MLP ###\n",
    "        C = nn.functional.relu(self.fo1(C.view(-1, self.P + self.Dx + (self.De))))\n",
    "        C = nn.functional.relu(self.fo2(C))\n",
    "        O = nn.functional.relu(self.fo3(C).view(-1, self.N, self.Do))\n",
    "        del C\n",
    "\n",
    "        \n",
    "        #Taking the sum of over each particle/vertex\n",
    "        N = torch.sum(O, dim=1)\n",
    "        del O\n",
    "        \n",
    "        ### Classification MLP ###\n",
    "\n",
    "        N = self.fc_fixed(N)\n",
    "        \n",
    "        if softmax:\n",
    "            N = nn.Softmax(dim=1)(N)\n",
    "        \n",
    "        return self.activation(N)\n",
    "            \n",
    "    def tmul(self, x, y):  #Takes (I * J * K)(K * L) -> I * J * L \n",
    "        x_shape = x.size()\n",
    "        y_shape = y.size()\n",
    "        return torch.mm(x.view(-1, x_shape[2]), y).view(-1, x_shape[1], y_shape[1])\n",
    "    \n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, n_targets):\n",
    "        super(DNN, self).__init__()\n",
    "        #self.flat = torch.flatten()\n",
    "        self.f0 = nn.Linear(200, 400).cuda()\n",
    "        self.f0b = nn.Linear(400, 400).cuda()\n",
    "        self.f1 = nn.Linear(400, 100).cuda()\n",
    "        self.f2 = nn.Linear(100, 50).cuda()\n",
    "        self.f3 = nn.Linear(50, 10).cuda()\n",
    "        self.f4 = nn.Linear(10, n_targets).cuda()\n",
    "        self.activation = torch.nn.ReLU()\n",
    "    def forward(self, x): \n",
    "        x = torch.flatten(x,start_dim=1)\n",
    "        x = self.activation(self.f0(x))\n",
    "        #x = self.f0b(x)\n",
    "        x = self.activation(self.f1(x))\n",
    "        x = self.activation(self.f2(x))\n",
    "        x = self.activation(self.f3(x))\n",
    "        x = self.f4(x)\n",
    "        return(x)\n",
    "    \n",
    "\n",
    "class simple_MLP(torch.nn.Module):\n",
    "    def __init__(self,input_size=5,out_channels=2,act_out=True,nlayers=4,nhidden=50,batchnorm=True):\n",
    "        super().__init__()\n",
    "        self.bn  = torch.nn.BatchNorm1d(input_size).cuda()\n",
    "        self.fc1 = torch.nn.Linear(input_size, 50, bias=False).cuda()\n",
    "        self.ac1 = torch.nn.ReLU().cuda()\n",
    "        self.dp1 = torch.nn.Dropout(p=0.2).cuda()\n",
    "        self.fc2 = torch.nn.Linear(50, 30).cuda()\n",
    "        self.ac2 = torch.nn.ReLU().cuda()\n",
    "        self.fc3 = torch.nn.Linear(30, 10).cuda()\n",
    "        self.ac3 = torch.nn.ReLU().cuda()\n",
    "        self.fc4 = torch.nn.Linear(10, out_channels).cuda()\n",
    "        self.output = torch.nn.Sigmoid().cuda()\n",
    "        self.out_channels = out_channels\n",
    "        self.act_out = act_out\n",
    "        self.nlayers = nlayers\n",
    "        self.runbatchnorm = batchnorm\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn(x)\n",
    "        x = self.fc1(x)\n",
    "        #x = self.ac1(x)\n",
    "        x = self.fc2(x)\n",
    "        #x = self.ac2(x)\n",
    "        x = self.fc3(x)\n",
    "        #x = self.ac3(x)\n",
    "        x = self.fc4(x)\n",
    "        #if self.runbatchnorm:\n",
    "        #    x = self.batchnorm(x)\n",
    "        #if self.act_out:\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f28b20fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define losses \n",
    "class BarlowTwinsLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, lambda_param=5e-3):\n",
    "        super(BarlowTwinsLoss, self).__init__()\n",
    "        self.lambda_param = lambda_param\n",
    "        self.device = torch.device('cuda:0')\n",
    "\n",
    "    def forward(self, z_a: torch.Tensor, z_b: torch.Tensor):\n",
    "        #self.device = (torch.device('cuda')if z_a.is_cuda else torch.device('cpu'))\n",
    "        # normalize repr. along the batch dimension\n",
    "        z_a_norm = (z_a - z_a.mean(0)) / z_a.std(0) # NxD\n",
    "        z_b_norm = (z_b - z_b.mean(0)) / z_b.std(0) # NxD\n",
    "\n",
    "        N = z_a.size(0)\n",
    "        D = z_a.size(1)\n",
    "\n",
    "        # cross-correlation matrix\n",
    "        c = torch.mm(z_a_norm.T, z_b_norm) / N # DxD\n",
    "        # loss\n",
    "        c_diff = (c - torch.eye(D, device=self.device)).pow(2) # DxD\n",
    "        # multiply off-diagonal elems of c_diff by lambda\n",
    "        c_diff[~torch.eye(D, dtype=bool)] *= self.lambda_param\n",
    "        loss = c_diff.sum()\n",
    "        return loss\n",
    "\n",
    "class CorrLoss(nn.Module):\n",
    "    def __init__(self, corr=False,sort_tolerance=1.0,sort_reg='l2'):\n",
    "        super(CorrLoss, self).__init__()\n",
    "        self.tolerance = sort_tolerance\n",
    "        self.reg       = sort_reg\n",
    "        self.corr      = corr\n",
    "        \n",
    "    def spearman(self, pred, target):\n",
    "        pred   = soft_rank(pred.cpu().reshape(1,-1),regularization=self.reg,regularization_strength=self.tolerance,)\n",
    "        target = soft_rank(target.cpu().reshape(1,-1),regularization=self.reg,regularization_strength=self.tolerance,)\n",
    "        #pred   = torchsort.soft_rank(pred.reshape(1,-1),regularization_strength=x)\n",
    "        #target = torchsort.soft_rank(target.reshape(1,-1),regularization_strength=x)\n",
    "        pred = pred - pred.mean()\n",
    "        pred = pred / pred.norm()\n",
    "        target = target - target.mean()\n",
    "        target = target / target.norm()\n",
    "        ret = (pred * target).sum()\n",
    "        if self.corr:\n",
    "            return (1-ret)*(1-ret)\n",
    "        else:\n",
    "            return ret*ret \n",
    "    \n",
    "    def forward(self, features, labels):\n",
    "        return self.spearman(features,labels)\n",
    "    \n",
    "class VICRegLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, lambda_param=1,mu_param=1,nu_param=20):\n",
    "        super(VICRegLoss, self).__init__()\n",
    "        self.lambda_param = lambda_param\n",
    "        self.mu_param = mu_param\n",
    "        self.nu_param = nu_param\n",
    "        #self.device = torch.device('cpu')\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        self.device = (torch.device('cuda')if x.is_cuda else torch.device('cpu'))\n",
    "        \n",
    "        x_scale = x\n",
    "        y_scale = y\n",
    "        repr_loss = F.mse_loss(x_scale, y_scale)\n",
    "        \n",
    "        #x = torch.cat(FullGatherLayer.apply(x), dim=0)\n",
    "        #y = torch.cat(FullGatherLayer.apply(y), dim=0)\n",
    "        x = x_scale - x_scale.mean(dim=0)\n",
    "        y = y_scale - y_scale.mean(dim=0)\n",
    "        N = x_scale.size(0)\n",
    "        D = x_scale.size(1)\n",
    "        \n",
    "        std_x = torch.sqrt(x_scale.var(dim=0) + 0.0001)\n",
    "        std_y = torch.sqrt(y_scale.var(dim=0) + 0.0001)\n",
    "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
    "\n",
    "        cov_x = (x_scale.T @ x_scale) / (N - 1)\n",
    "        cov_y = (y_scale.T @ y_scale) / (N - 1)\n",
    "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(D) + off_diagonal(cov_y).pow_(2).sum().div(D)\n",
    "\n",
    "        #loss = (self.lambda_param * repr_loss + self.mu_param * std_loss+ self.nu_param * cov_loss)\n",
    "        #print(repr_loss,cov_loss,std_loss)\n",
    "        return repr_loss,cov_loss,std_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d1c614dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 186/186 [01:32<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in 94.1340 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "/tmp/ipykernel_7066/2378093231.py:196: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k+\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axs[dim].plot(out1_val[:int(batchSize/2), dim], trainingv1_val_mass[:int(batchSize/2)], 'k+',c='r', alpha=0.5)\n",
      "/tmp/ipykernel_7066/2378093231.py:198: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k+\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axs[dim].plot(out1_val[int(batchSize/2):, dim], trainingv1_val_mass[int(batchSize/2):], 'k+',c='b', alpha=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done in 22.2227 seconds\n",
      "\n",
      "Validation Loss:  10.996691579404084\n",
      "Training Loss:  12.64468668353173\n",
      "new best model\n",
      "(138000, 2) (138000, 8)\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]] [[-0.01381169 -0.1162011   0.0605428  ... -0.09493644 -0.01851977\n",
      "  -0.18651107]\n",
      " [-0.01501959 -0.12449077  0.0545233  ... -0.10223212 -0.01691175\n",
      "  -0.18116176]\n",
      " [-0.01678154 -0.13144246  0.03866694 ... -0.0999267  -0.01548634\n",
      "  -0.18182462]\n",
      " ...\n",
      " [-0.01992276 -0.12834133  0.0549212  ... -0.09756334 -0.00939825\n",
      "  -0.18542203]\n",
      " [-0.02263954 -0.12990314  0.05731303 ... -0.09897024 -0.00758275\n",
      "  -0.18468481]\n",
      " [-0.01929378 -0.13291514  0.04808735 ... -0.08550946  0.00928604\n",
      "  -0.19593664]]\n",
      "Validation Accuracy:  0.4831376811594203\n",
      "Epoch 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 186/186 [01:26<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in 88.5125 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "/tmp/ipykernel_7066/2378093231.py:196: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k+\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axs[dim].plot(out1_val[:int(batchSize/2), dim], trainingv1_val_mass[:int(batchSize/2)], 'k+',c='r', alpha=0.5)\n",
      "/tmp/ipykernel_7066/2378093231.py:198: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k+\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axs[dim].plot(out1_val[int(batchSize/2):, dim], trainingv1_val_mass[int(batchSize/2):], 'k+',c='b', alpha=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done in 23.7967 seconds\n",
      "\n",
      "Validation Loss:  9.503867978635041\n",
      "Training Loss:  10.209125534180671\n",
      "new best model\n",
      "(138000, 2) (138000, 8)\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]] [[-0.01316097 -0.12341636  0.02900838 ... -0.09414788 -0.02177226\n",
      "  -0.17297243]\n",
      " [-0.01680594 -0.12713632  0.03844653 ... -0.09887469 -0.01995288\n",
      "  -0.17091456]\n",
      " [-0.01920921 -0.13262352  0.02251204 ... -0.09926622 -0.02124819\n",
      "  -0.16932729]\n",
      " ...\n",
      " [-0.02086151 -0.1273694   0.03531516 ... -0.09712991 -0.01622048\n",
      "  -0.1722001 ]\n",
      " [-0.02274702 -0.13244857  0.054981   ... -0.08855294 -0.00296657\n",
      "  -0.18189676]\n",
      " [-0.02072089 -0.1319712   0.03398747 ... -0.09436348 -0.00830954\n",
      "  -0.17528465]]\n",
      "Validation Accuracy:  0.4831376811594203\n",
      "Epoch 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 186/186 [01:32<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in 93.9626 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "/tmp/ipykernel_7066/2378093231.py:196: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k+\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axs[dim].plot(out1_val[:int(batchSize/2), dim], trainingv1_val_mass[:int(batchSize/2)], 'k+',c='r', alpha=0.5)\n",
      "/tmp/ipykernel_7066/2378093231.py:198: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k+\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axs[dim].plot(out1_val[int(batchSize/2):, dim], trainingv1_val_mass[int(batchSize/2):], 'k+',c='b', alpha=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done in 22.8042 seconds\n",
      "\n",
      "Validation Loss:  8.682219505310059\n",
      "Training Loss:  9.05306629468036\n",
      "new best model\n",
      "(138000, 2) (138000, 8)\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]] [[-0.01586011 -0.12112968  0.01660873 ... -0.08745228 -0.01506362\n",
      "  -0.17059572]\n",
      " [-0.02236331 -0.1274486   0.03089824 ... -0.09135659 -0.0153816\n",
      "  -0.1693109 ]\n",
      " [-0.02489051 -0.13255782  0.01890455 ... -0.09121869 -0.01629545\n",
      "  -0.1685509 ]\n",
      " ...\n",
      " [-0.02380805 -0.12830903  0.0217975  ... -0.08914063 -0.01242664\n",
      "  -0.17044029]\n",
      " [-0.0266823  -0.13041711  0.0500478  ... -0.07967988  0.00162171\n",
      "  -0.1813607 ]\n",
      " [-0.02225274 -0.13101095  0.03262817 ... -0.08778161 -0.00557493\n",
      "  -0.17329513]]\n",
      "Validation Accuracy:  0.4831376811594203\n",
      "Epoch 3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 186/186 [01:29<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in 90.9881 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "/tmp/ipykernel_7066/2378093231.py:196: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k+\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axs[dim].plot(out1_val[:int(batchSize/2), dim], trainingv1_val_mass[:int(batchSize/2)], 'k+',c='r', alpha=0.5)\n",
      "/tmp/ipykernel_7066/2378093231.py:198: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k+\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axs[dim].plot(out1_val[int(batchSize/2):, dim], trainingv1_val_mass[int(batchSize/2):], 'k+',c='b', alpha=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done in 22.9294 seconds\n",
      "\n",
      "Validation Loss:  8.25534260791281\n",
      "Training Loss:  8.462878734834733\n",
      "new best model\n",
      "(138000, 2) (138000, 8)\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]] [[-0.01798126 -0.1259644   0.01040622 ... -0.08608579 -0.01477103\n",
      "  -0.16940987]\n",
      " [-0.02294913 -0.12782833  0.02747638 ... -0.08881399 -0.0147627\n",
      "  -0.16898976]\n",
      " [-0.02657123 -0.1327551   0.01342045 ... -0.08853924 -0.0160121\n",
      "  -0.16814387]\n",
      " ...\n",
      " [-0.02523846 -0.12948896  0.01418249 ... -0.08691778 -0.01292581\n",
      "  -0.16949731]\n",
      " [-0.02833778 -0.12956999  0.04590926 ... -0.07712258  0.00167817\n",
      "  -0.18085562]\n",
      " [-0.0212898  -0.1313528   0.03011162 ... -0.08596445 -0.00630782\n",
      "  -0.17234527]]\n",
      "Validation Accuracy:  0.4831376811594203\n",
      "Epoch 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 186/186 [01:28<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in 90.0730 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "/tmp/ipykernel_7066/2378093231.py:196: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k+\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axs[dim].plot(out1_val[:int(batchSize/2), dim], trainingv1_val_mass[:int(batchSize/2)], 'k+',c='r', alpha=0.5)\n",
      "/tmp/ipykernel_7066/2378093231.py:198: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k+\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axs[dim].plot(out1_val[int(batchSize/2):, dim], trainingv1_val_mass[int(batchSize/2):], 'k+',c='b', alpha=0.5)\n",
      "/uscms_data/d3/jkrupa/flat/mambaforge/envs/IN/lib/python3.10/site-packages/corner/core.py:95: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = pl.subplots(K, K, figsize=(dim, dim))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done in 23.2024 seconds\n",
      "\n",
      "Validation Loss:  8.03004853621773\n",
      "Training Loss:  8.140179880203739\n",
      "new best model\n",
      "(138000, 2) (138000, 8)\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]] [[-0.01822238 -0.12819245  0.00817222 ... -0.08597846 -0.01630147\n",
      "  -0.16900074]\n",
      " [-0.02341923 -0.12861668  0.02629629 ... -0.08885368 -0.01552228\n",
      "  -0.16858779]\n",
      " [-0.02738418 -0.13423344  0.01076196 ... -0.08904761 -0.01737352\n",
      "  -0.1672412 ]\n",
      " ...\n",
      " [-0.02579007 -0.13001859  0.01196581 ... -0.08680058 -0.01389646\n",
      "  -0.16908583]\n",
      " [-0.02934102 -0.13068154  0.04102885 ... -0.07696306  0.00074051\n",
      "  -0.18031257]\n",
      " [-0.02023019 -0.1300282   0.02807399 ... -0.08478886 -0.00703757\n",
      "  -0.17263627]]\n",
      "Validation Accuracy:  0.4831376811594203\n",
      "Epoch 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 186/186 [01:32<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in 94.4878 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "/tmp/ipykernel_7066/2378093231.py:196: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k+\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axs[dim].plot(out1_val[:int(batchSize/2), dim], trainingv1_val_mass[:int(batchSize/2)], 'k+',c='r', alpha=0.5)\n",
      "/tmp/ipykernel_7066/2378093231.py:198: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k+\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axs[dim].plot(out1_val[int(batchSize/2):, dim], trainingv1_val_mass[int(batchSize/2):], 'k+',c='b', alpha=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done in 22.6615 seconds\n",
      "\n",
      "Validation Loss:  7.876104375590449\n",
      "Training Loss:  7.951818922514557\n",
      "new best model\n",
      "(138000, 2) (138000, 8)\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]] [[-1.8871317e-02 -1.3164167e-01  4.2136116e-03 ... -8.6348101e-02\n",
      "  -1.7664848e-02 -1.6883649e-01]\n",
      " [-2.3908550e-02 -1.3083914e-01  1.9761711e-02 ... -8.9346267e-02\n",
      "  -1.7274899e-02 -1.6801140e-01]\n",
      " [-2.8394565e-02 -1.3648233e-01  3.1180959e-03 ... -8.9804314e-02\n",
      "  -1.9430423e-02 -1.6635455e-01]\n",
      " ...\n",
      " [-2.6161065e-02 -1.3213512e-01  9.2557166e-03 ... -8.6928979e-02\n",
      "  -1.4636384e-02 -1.6919659e-01]\n",
      " [-2.8509988e-02 -1.3220538e-01  3.6120199e-02 ... -7.6807059e-02\n",
      "   7.1302056e-06 -1.8040250e-01]\n",
      " [-2.0318175e-02 -1.3271162e-01  2.3447048e-02 ... -8.5650221e-02\n",
      "  -9.2364792e-03 -1.7191544e-01]]\n",
      "Validation Accuracy:  0.4831376811594203\n",
      "Epoch 6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 186/186 [01:30<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in 91.7751 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "/tmp/ipykernel_7066/2378093231.py:196: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k+\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axs[dim].plot(out1_val[:int(batchSize/2), dim], trainingv1_val_mass[:int(batchSize/2)], 'k+',c='r', alpha=0.5)\n",
      "/tmp/ipykernel_7066/2378093231.py:198: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k+\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axs[dim].plot(out1_val[int(batchSize/2):, dim], trainingv1_val_mass[int(batchSize/2):], 'k+',c='b', alpha=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done in 22.1405 seconds\n",
      "\n",
      "Validation Loss:  7.780813528143841\n",
      "Training Loss:  7.827348496324273\n",
      "new best model\n",
      "(138000, 2) (138000, 8)\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]] [[-0.01718576 -0.13533707 -0.00041762 ... -0.08435107 -0.01648632\n",
      "  -0.17017835]\n",
      " [-0.02346403 -0.13442893  0.01736565 ... -0.08721294 -0.01506433\n",
      "  -0.1697337 ]\n",
      " [-0.0280086  -0.13823713  0.0006728  ... -0.08916105 -0.01938057\n",
      "  -0.16666014]\n",
      " ...\n",
      " [-0.02660916 -0.1346294   0.01059168 ... -0.08533135 -0.01239769\n",
      "  -0.17077973]\n",
      " [-0.02702281 -0.13326323  0.03240993 ... -0.07580461  0.00083688\n",
      "  -0.18090023]\n",
      " [-0.02060533 -0.13427243  0.01953692 ... -0.08558796 -0.01020334\n",
      "  -0.17156017]]\n",
      "Validation Accuracy:  0.4831376811594203\n",
      "Epoch 7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 186/186 [01:29<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in 91.6371 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "/tmp/ipykernel_7066/2378093231.py:196: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k+\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axs[dim].plot(out1_val[:int(batchSize/2), dim], trainingv1_val_mass[:int(batchSize/2)], 'k+',c='r', alpha=0.5)\n",
      "/tmp/ipykernel_7066/2378093231.py:198: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k+\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axs[dim].plot(out1_val[int(batchSize/2):, dim], trainingv1_val_mass[int(batchSize/2):], 'k+',c='b', alpha=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done in 23.1974 seconds\n",
      "\n",
      "Validation Loss:  7.6944572614586875\n",
      "Training Loss:  7.7394900629597325\n",
      "new best model\n",
      "(138000, 2) (138000, 8)\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]] [[-1.62108690e-02 -1.33542657e-01  1.79103110e-03 ... -8.31198022e-02\n",
      "  -1.58510078e-02 -1.72219887e-01]\n",
      " [-2.28103809e-02 -1.32339939e-01  1.90577507e-02 ... -8.70490521e-02\n",
      "  -1.56429131e-02 -1.70809567e-01]\n",
      " [-2.79587787e-02 -1.36976406e-01 -8.06724653e-04 ... -8.97428319e-02\n",
      "  -2.07973253e-02 -1.66881651e-01]\n",
      " ...\n",
      " [-2.53872592e-02 -1.33812785e-01  7.29069114e-03 ... -8.58756751e-02\n",
      "  -1.40093174e-02 -1.70887008e-01]\n",
      " [-2.51686908e-02 -1.30869642e-01  3.22034657e-02 ... -7.59938508e-02\n",
      "   1.10683963e-04 -1.81519300e-01]\n",
      " [-2.01983172e-02 -1.34736910e-01  1.65736992e-02 ... -8.61257315e-02\n",
      "  -1.15520265e-02 -1.71793580e-01]]\n",
      "Validation Accuracy:  0.4831376811594203\n",
      "Epoch 8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 186/186 [01:28<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in 90.0110 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "/tmp/ipykernel_7066/2378093231.py:196: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k+\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axs[dim].plot(out1_val[:int(batchSize/2), dim], trainingv1_val_mass[:int(batchSize/2)], 'k+',c='r', alpha=0.5)\n",
      "/tmp/ipykernel_7066/2378093231.py:198: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k+\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axs[dim].plot(out1_val[int(batchSize/2):, dim], trainingv1_val_mass[int(batchSize/2):], 'k+',c='b', alpha=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done in 21.9305 seconds\n",
      "\n",
      "Validation Loss:  7.660012307374374\n",
      "Training Loss:  7.6711194002500145\n",
      "new best model\n",
      "(138000, 2) (138000, 8)\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]] [[-0.0153524  -0.13519095  0.00271793 ... -0.08293867 -0.01366262\n",
      "  -0.17221089]\n",
      " [-0.02270547 -0.1333401   0.01845337 ... -0.08669026 -0.01366657\n",
      "  -0.17075059]\n",
      " [-0.02714916 -0.13831319 -0.00213474 ... -0.08921456 -0.01861615\n",
      "  -0.1669173 ]\n",
      " ...\n",
      " [-0.02432616 -0.13484976  0.00861945 ... -0.08726542 -0.01344074\n",
      "  -0.16955441]\n",
      " [-0.02378089 -0.13127008  0.03185553 ... -0.07603952  0.00172994\n",
      "  -0.18110932]\n",
      " [-0.0181886  -0.13463254  0.0164541  ... -0.08572287 -0.00951678\n",
      "  -0.17176227]]\n",
      "Validation Accuracy:  0.4831376811594203\n",
      "Epoch 9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 186/186 [01:30<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done in 91.9967 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "/tmp/ipykernel_7066/2378093231.py:196: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k+\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axs[dim].plot(out1_val[:int(batchSize/2), dim], trainingv1_val_mass[:int(batchSize/2)], 'k+',c='r', alpha=0.5)\n",
      "/tmp/ipykernel_7066/2378093231.py:198: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k+\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axs[dim].plot(out1_val[int(batchSize/2):, dim], trainingv1_val_mass[int(batchSize/2):], 'k+',c='b', alpha=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done in 22.7173 seconds\n",
      "\n",
      "Validation Loss:  7.606669882069463\n",
      "Training Loss:  7.620186523724628\n",
      "new best model\n",
      "(138000, 2) (138000, 8)\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]] [[-1.36818215e-02 -1.35449156e-01  1.49775296e-04 ... -8.39765370e-02\n",
      "  -1.48297902e-02 -1.69662625e-01]\n",
      " [-2.25579403e-02 -1.31953120e-01  1.35392649e-02 ... -8.91417041e-02\n",
      "  -1.66420247e-02 -1.66709602e-01]\n",
      " [-2.64924578e-02 -1.38177991e-01 -2.45480798e-03 ... -8.93638209e-02\n",
      "  -1.72808710e-02 -1.65471077e-01]\n",
      " ...\n",
      " [-2.41292976e-02 -1.34589583e-01  6.42347615e-03 ... -8.77820104e-02\n",
      "  -1.24757532e-02 -1.67627126e-01]\n",
      " [-2.18156036e-02 -1.29942730e-01  3.20422985e-02 ... -7.83380494e-02\n",
      "   8.02818686e-04 -1.77804008e-01]\n",
      " [-1.75553598e-02 -1.34444296e-01  1.36160348e-02 ... -8.71558413e-02\n",
      "  -9.59387235e-03 -1.68992430e-01]]\n",
      "Validation Accuracy:  0.4831376811594203\n",
      "DONE with DNN training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x4320 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x3600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1303.2x1303.2 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x4320 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x3600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1303.2x1303.2 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x4320 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x3600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1303.2x1303.2 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x4320 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x3600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1303.2x1303.2 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x4320 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x3600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1303.2x1303.2 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x4320 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x3600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1303.2x1303.2 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x4320 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x3600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1303.2x1303.2 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x4320 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x3600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1303.2x1303.2 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x4320 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x3600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1303.2x1303.2 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x4320 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x3600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1303.2x1303.2 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Training Loop Barlow DNN #########\n",
    "\n",
    "batchSize = 6000\n",
    "n_epochs = 10\n",
    "\n",
    "gnn = DNN(n_encoded_nodes)\n",
    "    \n",
    "loss = nn.BCELoss(reduction='mean')\n",
    "clr_criterion  = BarlowTwinsLoss(lambda_param=1.0)\n",
    "cor_criterion  = CorrLoss()\n",
    "acr_criterion  = CorrLoss(corr=True)\n",
    "\n",
    "BarlowLoss = True\n",
    "\n",
    "optimizer = optim.Adam(gnn.parameters(), lr = 0.0001)\n",
    "loss_vals_training = np.zeros(n_epochs)\n",
    "loss_std_training = np.zeros(n_epochs)\n",
    "loss_vals_validation = np.zeros(n_epochs)\n",
    "loss_std_validation = np.zeros(n_epochs)\n",
    "\n",
    "acc_vals_training = np.zeros(n_epochs)\n",
    "acc_vals_validation = np.zeros(n_epochs)\n",
    "acc_std_training = np.zeros(n_epochs)\n",
    "acc_std_validation = np.zeros(n_epochs)\n",
    "\n",
    "final_epoch = 0\n",
    "l_val_best = 99999\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "import time\n",
    "from tqdm import tqdm \n",
    "\n",
    "for m in range(n_epochs):\n",
    "    print(\"Epoch %s\\n\" % m)\n",
    "    torch.cuda.empty_cache()\n",
    "    final_epoch = m\n",
    "    lst = []\n",
    "    loss_val = []\n",
    "    loss_training = []\n",
    "    correct = []\n",
    "    tic = time.perf_counter()\n",
    "    \n",
    "    particleTrainingDataSig, jetMassTrainingDataSig = sklearn.utils.shuffle(particleTrainingDataSig, jetMassTrainingDataSig)\n",
    "    particleTrainingDataBkg, jetMassTrainingDataBkg = sklearn.utils.shuffle(particleTrainingDataBkg, jetMassTrainingDataBkg)\n",
    "    particleValidationDataSig, jetMassValidationDataSig = sklearn.utils.shuffle(particleValidationDataSig,\n",
    "                                                                                jetMassValidationDataSig)\n",
    "    particleValidationDataBkg, jetMassValidationDataBkg = sklearn.utils.shuffle(particleValidationDataBkg,\n",
    "                                                                                jetMassValidationDataBkg)\n",
    "    \n",
    "\n",
    "    out1_totSig = np.empty((0,n_encoded_nodes))\n",
    "    out1_totBkg = np.empty((0,n_encoded_nodes))\n",
    "\n",
    "    trainingv1_mass_totSig = []\n",
    "    trainingv1_mass_totBkg = []\n",
    "\n",
    "    #print(out1_tot)\n",
    "    for i in tqdm(range(int(0.8*datapoints/batchSize))): \n",
    "        #print('%s out of %s'%(i, int(particleTrainingData.shape[0]/batchSize)))\n",
    "        optimizer.zero_grad()\n",
    "        trainingvSig = torch.Tensor(particleTrainingDataSig[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        trainingvBkg = torch.Tensor(particleTrainingDataBkg[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        trainingvMassSig = torch.Tensor(jetMassTrainingDataSig[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        trainingvMassBkg = torch.Tensor(jetMassTrainingDataBkg[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        trainingv1 = torch.cat((trainingvSig[:int(batchSize/2)], \n",
    "                                trainingvBkg[:int(batchSize/2)]))\n",
    "        trainingv1_mass = torch.cat((trainingvMassSig[:int(batchSize/2)], \n",
    "                                trainingvMassBkg[:int(batchSize/2)]))\n",
    "        trainingv2 = torch.cat((trainingvSig[int(batchSize/2):], \n",
    "                                trainingvBkg[int(batchSize/2):]))\n",
    "        \n",
    "        # Calculate network output\n",
    "        out1 = gnn(trainingv1)\n",
    "        out2 = gnn(trainingv2)\n",
    "        \n",
    "        # Barlow Loss\n",
    "        lossClr = weightClr*clr_criterion(out1, out2)\n",
    "        \n",
    "        # AntiCorrelation\n",
    "        lossCorr1 = weightCorr1*acr_criterion(trainingv1_mass, out1[:,0])\n",
    "        l = lossClr + lossCorr1\n",
    "       \n",
    "        # Correlation for rest of dimensions\n",
    "        for dim in range(out1.shape[1]-1): \n",
    "            l += weightCorr2*cor_criterion(out1[:,dim+1], trainingv1_mass)\n",
    "        \n",
    "        #l = weightClr*lossClr  + weightCorr1*lossCorr1 + weightCorr2*lossCorr2 + lossCorr3\n",
    "        \n",
    "        # Classical BCE loss\n",
    "        #trainingv = torch.FloatTensor(particleTrainingData[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        #out = gnn(trainingv)\n",
    "        #targetv = torch.FloatTensor(trainingLabels[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        #l = loss(out, targetv)\n",
    "        \n",
    "        \n",
    "        loss_training.append(l.item())\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        loss_string = \"Loss: %s\" % \"{0:.5f}\".format(l.item())\n",
    "        out1 = out1.cpu().detach().numpy()\n",
    "        out1_totSig = np.concatenate((out1_totSig,out1[:int(batchSize/2)]))\n",
    "        out1_totBkg = np.concatenate((out1_totBkg,out1[int(batchSize/2):]))\n",
    "\n",
    "        trainingv1_mass = trainingv1_mass.cpu().detach().numpy().tolist()\n",
    "        trainingv1_mass_totSig += trainingv1_mass[:int(batchSize/2)]\n",
    "        trainingv1_mass_totBkg += trainingv1_mass[int(batchSize/2):]\n",
    "\n",
    "        #print(\"SIG:\", trainingv1_mass_totSig)\n",
    "        #print(\"BKG:\", trainingv1_mass_totBkg)\n",
    "\n",
    "        del trainingvSig, trainingvBkg, l, trainingv1, trainingv2#, out1, out2, trainingv1_mass\n",
    "        torch.cuda.empty_cache()\n",
    "    #trainingv1_mass_tot = np.array(trainingv1_mass_tot)       \n",
    "    toc = time.perf_counter()\n",
    "    print(f\"Training done in {toc - tic:0.4f} seconds\")\n",
    "    tic = time.perf_counter()\n",
    "\n",
    "    \n",
    "    plt.clf()\n",
    "    fig, axs = plt.subplots(n_encoded_nodes,2, figsize=(10,dim*10))\n",
    "    \n",
    "    axs[0,0].text(0.05,2.8, loss_text, transform=ax.transAxes)\n",
    "\n",
    "    for dim in range(out1.shape[1]): \n",
    "        outSig, massSig = out1_totSig[:, dim].copy(), trainingv1_mass_totSig[:].copy()\n",
    "        outSig -= np.mean(outSig)\n",
    "        outSig /= np.std(outSig)\n",
    "        massSig -= np.mean(massSig)\n",
    "        massSig /= np.std(massSig)\n",
    "\n",
    "        outBkg, massBkg = out1_totBkg[:, dim].copy(), trainingv1_mass_totBkg[:].copy()\n",
    "        outBkg -= np.mean(outBkg)\n",
    "        outBkg /= np.std(outBkg)\n",
    "        massBkg -= np.mean(massBkg)\n",
    "        massBkg /= np.std(massBkg)\n",
    "\n",
    "        \n",
    "        axs[dim,0].text(0.8,1.03,f\"Z' Corr:  {np.corrcoef(outSig, massSig)[0,1] : .4f}\", transform=axs[dim,0].transAxes)\n",
    "        axs[dim,0].hist2d(outSig, trainingv1_mass_totSig[:], bins=30, )\n",
    "        axs[dim,1].text(0.8,1.03,f\"QCD Corr: {np.corrcoef(outBkg, massBkg)[0,1] : .4f}\", transform=axs[dim,1].transAxes)\n",
    "        axs[dim,1].hist2d(outBkg, trainingv1_mass_totBkg[:], bins=30, )\n",
    "        axs[dim,0].set_xlim([-3.,3.])\n",
    "        axs[dim,1].set_xlim([-3.,3.])\n",
    "        axs[dim,0].set_xlabel(f'Dimension {dim} output')\n",
    "        axs[dim,1].set_xlabel(f'Dimension {dim} output')\n",
    "        axs[dim,0].set_ylabel('Jet mass (GeV)')\n",
    "        \n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(outdir+\"/\"+label+f\"_contrastivefigIN_trainingDataset_epoch{m}.jpg\")\n",
    "    del out1, out2, trainingv1_mass\n",
    "\n",
    "    \n",
    "    for i in range(int(0.1*datapoints/(batchSize))): \n",
    "        torch.cuda.empty_cache()\n",
    "        trainingvSig_val = torch.Tensor(particleValidationDataSig[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        trainingvBkg_val = torch.Tensor(particleValidationDataBkg[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        trainingvMassSig_val = torch.Tensor(jetMassValidationDataSig[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        trainingvMassBkg_val = torch.Tensor(jetMassValidationDataBkg[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        targetv_val = torch.Tensor(validationLabels[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        trainingv1_val = torch.cat((trainingvSig_val[:int(batchSize/2)], trainingvBkg_val[:int(batchSize/2)]))\n",
    "        trainingv2_val = torch.cat((trainingvSig_val[int(batchSize/2):], trainingvBkg_val[int(batchSize/2):]))\n",
    "        trainingv1_val_mass = torch.cat((trainingvMassSig_val[:int(batchSize/2)], \n",
    "                                trainingvMassBkg_val[:int(batchSize/2)]))\n",
    "        \n",
    "        # Barlow Loss\n",
    "        out1_val = gnn(trainingv1_val)\n",
    "        out2_val = gnn(trainingv2_val)\n",
    "        lossClr = weightClr*clr_criterion(out1_val, out2_val)\n",
    "        \n",
    "        # AntiCorrelation\n",
    "        lossCorr1 = weightCorr1*acr_criterion(trainingv1_val_mass, out1_val[:,0])\n",
    "        l_val = lossClr + lossCorr1\n",
    "       \n",
    "        # Correlation for rest of dimensions\n",
    "        for dim in range(out1_val.shape[1]-1): \n",
    "            l_val += (dim+1)*cor_criterion(out1_val[:,dim+1], trainingv1_val_mass)\n",
    "        \n",
    "        \n",
    "        # Classical validation\n",
    "        trainingv_val = torch.Tensor(particleValidationData[i*batchSize:(i+1)*batchSize]).cuda()\n",
    "        out = gnn(trainingv_val)\n",
    "        # l_val = loss(out, targetv_val)\n",
    "        lst.append(out.cpu().data.numpy())\n",
    "        loss_val.append(l_val.item())\n",
    "        correct.append(targetv_val.cpu())\n",
    "        out1_val = out1_val.cpu().detach().numpy()\n",
    "        trainingv1_val_mass = trainingv1_val_mass.cpu().detach().numpy()\n",
    "        \n",
    "        \n",
    "        del trainingvSig_val, trainingvBkg_val, targetv_val, trainingv1_val, trainingv2_val,out2_val\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.clf()\n",
    "    fig, axs = plt.subplots(n_encoded_nodes, figsize=(10,50))\n",
    "    for dim in range(out1_val.shape[1]): \n",
    "        axs[dim].plot(out1_val[:int(batchSize/2), dim], trainingv1_val_mass[:int(batchSize/2)], 'k+',c='r', alpha=0.5)\n",
    "        #plt.xlabel('%s dimension output'%(dim))\n",
    "        axs[dim].plot(out1_val[int(batchSize/2):, dim], trainingv1_val_mass[int(batchSize/2):], 'k+',c='b', alpha=0.5)\n",
    "\n",
    "        axs[dim].set_ylabel('sdmass')\n",
    "    plt.savefig(outdir+\"/\"+label+\"_contrastivefigIN_validationDataset.jpg\")\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.figure()\n",
    "    fig = corner.corner(out1_val[:int(batchSize/2)], color='red')\n",
    "    corner.corner(out1_val[int(batchSize/2):], fig=fig, color='blue')\n",
    "    plt.savefig(outdir+\"/\"+label+\"corner.jpg\")\n",
    "    plt.clf()\n",
    "    del out1_val, trainingv1_val_mass\n",
    "    #targetv_cpu = targetv.cpu().data.numpy()\n",
    "    \n",
    "    toc = time.perf_counter()\n",
    "    print(f\"Evaluation done in {toc - tic:0.4f} seconds\")\n",
    "    l_val = np.mean(np.array(loss_val))\n",
    "\n",
    "    predicted = np.concatenate(lst) #(torch.FloatTensor(np.concatenate(lst))).to(device)\n",
    "    print('\\nValidation Loss: ', l_val)\n",
    "\n",
    "    l_training = np.mean(np.array(loss_training))\n",
    "    print('Training Loss: ', l_training)\n",
    "    val_targetv = np.concatenate(correct) #torch.FloatTensor(np.array(correct)).cuda()\n",
    "\n",
    "    torch.save(gnn.state_dict(), '%s/DNN_%s_last.pth'%(outdir,label))\n",
    "    if l_val < l_val_best:\n",
    "        print(\"new best model\")\n",
    "        l_val_best = l_val\n",
    "        torch.save(gnn.state_dict(), '%s/DNN_%s_best.pth'%(outdir,label))\n",
    "\n",
    "    print(val_targetv.shape, predicted.shape)\n",
    "    print(val_targetv, predicted)\n",
    "    acc_vals_validation[m] = accuracy_score(val_targetv[:,0],predicted[:,0]>0.5)\n",
    "    print(\"Validation Accuracy: \", acc_vals_validation[m])\n",
    "    loss_vals_training[m] = l_training\n",
    "    loss_vals_validation[m] = l_val\n",
    "    loss_std_validation[m] = np.std(np.array(loss_val))\n",
    "    loss_std_training[m] = np.std(np.array(loss_training))\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if m > 8 and all(loss_vals_validation[max(0, m - 8):m] > min(np.append(loss_vals_validation[0:max(0, m - 8)], 200))):\n",
    "        print('Early Stopping...')\n",
    "        print(loss_vals_training, '\\n', np.diff(loss_vals_training))\n",
    "        break\n",
    "    torch.cuda.empty_cache()\n",
    "print('DONE with DNN training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "40b37a19",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.83 GiB (GPU 0; 11.91 GiB total capacity; 57.74 MiB already allocated; 284.06 MiB free; 128.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#torch.cuda.empty_cache()\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#r=torch.randperm(len(trainingLabels))\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m x_torch\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moutdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlabel\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_particleTrainingData.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m y_torch\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_trainingLabels.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      6\u001b[0m m_torch\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jetMassTrainingData.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.83 GiB (GPU 0; 11.91 GiB total capacity; 57.74 MiB already allocated; 284.06 MiB free; 128.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "\n",
    "#r=torch.randperm(len(trainingLabels))\n",
    "x_torch=torch.load(f\"{outdir}/{label}_particleTrainingData.pt\").cuda()\n",
    "y_torch=torch.load(f\"{outdir}/{label}_trainingLabels.pt\").cuda()\n",
    "m_torch=torch.load(f\"{outdir}/{label}_jetMassTrainingData.pt\").cuda()\n",
    "\n",
    "gnn = DNN(n_encoded_nodes)\n",
    "gnn.load_state_dict(torch.load('%s/DNN_%s_best.pth'%(outdir,label), map_location=torch.device('cuda')))\n",
    "gnn.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs_optimal_clr = gnn(x_torch)\n",
    "\n",
    "del x_torch\n",
    "torch.cuda.empty_cache()\n",
    "simple_model = simple_MLP(input_size=n_encoded_nodes-1)\n",
    "simple_optimizer = torch.optim.Adam(simple_model.parameters(), lr=.1) \n",
    "simple_criterion = torch.nn.BCELoss()\n",
    "\n",
    "for epoch in range(501):\n",
    "    simple_optimizer.zero_grad()\n",
    "    outputs = simple_model(outputs_optimal_clr[:,1:])\n",
    "    loss = simple_criterion(outputs,y_torch)\n",
    "    loss.backward()\n",
    "    simple_optimizer.step()\n",
    "    current_loss = float(loss.item())\n",
    "    if epoch % 10 == 1: \n",
    "        print(f\"Epoch {epoch} loss={current_loss:.5f}\")\n",
    "\n",
    "print(simple_model.state_dict())\n",
    "del simple_optimizer, loss, simple_model, simple_criterion\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69053458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score\n",
    "\n",
    "fig, ax=plt.subplots()\n",
    "ax.hist(outputs[y_torch[:,1]==0][:,1].cpu().detach().numpy(),color=\"r\",bins=np.linspace(0.,1.,25),alpha=0.5,label=\"QCD\")\n",
    "ax.hist(outputs[y_torch[:,1]==1][:,1].cpu().detach().numpy(),color=\"b\",bins=np.linspace(0.,1.,25),alpha=0.5,label=\"Z'\")\n",
    "plt.legend(loc=\"best\")\n",
    "ax.set_xlabel(\"Discriminator\")\n",
    "ax.set_ylabel(\"Counts\")\n",
    "ax.text(0.45,1.03,loss_text, transform=ax.transAxes)\n",
    "plt.savefig(outdir+\"/discriminatorHist.png\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax=plt.subplots()\n",
    "#print(outputs[:,0].cpu().detach().numpy(),y_torch[:,0].cpu().detach().numpy().astype(bool))\n",
    "fpr, tpr, _ = roc_curve(y_torch[:,0].cpu().detach().numpy(),outputs[:,0].cpu().detach().numpy(),)\n",
    "ax.plot(fpr, tpr)\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"True Positive Rate\")\n",
    "ax.text(0.45,1.03,loss_text, transform=ax.transAxes)\n",
    "ax.text(0.75,0.10, f\"AUC={roc_auc_score(y_torch[:,0].cpu().detach().numpy(),outputs[:,0].cpu().detach().numpy()) : 0.2f}\", transform=ax.transAxes)\n",
    "plt.savefig(outdir+\"/roc.png\")\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "# Calculate mass distribution after cuts\n",
    "\n",
    "hist, edges = np.histogram(outputs[y_torch[:,1].cpu().detach().numpy()==1][:,1].cpu().detach().numpy(), bins=np.linspace(0.,1.,100),density=True)\n",
    "cdf = np.cumsum(hist)*(edges[1]-edges[0])\n",
    "print(cdf)\n",
    "\n",
    "pctls = [0.,0.25,0.5,0.7,0.9,0.95,0.99]\n",
    "cuts = np.searchsorted(cdf,pctls)\n",
    "\n",
    "fig, ax=plt.subplots()\n",
    "\n",
    "qcd_idxs = y_torch[:,1].cpu().detach().numpy()==1\n",
    "qcd_inclusive, _ = np.histogram(\n",
    "        m_torch[(qcd_idxs)].cpu().detach().numpy(),\n",
    "        density=True,\n",
    "    )\n",
    "for c,p in zip(cuts,pctls):\n",
    "    passing_idxs = outputs[:,1].cpu().detach().numpy() > edges[c]\n",
    "    hist, bin_edges = np.histogram(\n",
    "        m_torch[(qcd_idxs&passing_idxs)].cpu().detach().numpy(), \n",
    "    )\n",
    "    N_passing = float(np.sum(hist))\n",
    "    qcd_passing = np.divide(hist,[N_passing])\n",
    "    jsd = scipy.spatial.distance.jensenshannon(qcd_passing, qcd_inclusive)\n",
    "\n",
    "    bins_centers = 0.5*(bin_edges[1:]+bin_edges[:-1])\n",
    "    ax.plot(\n",
    "        bins_centers, \n",
    "        qcd_passing,\n",
    "        label = f\"{(1-p)*100:.0f}% ({int(N_passing)}) JSD={0 if jsd == np.nan else jsd:.2f}\"\n",
    "    )\n",
    "ax.set_xlabel(\"Jet mass (GeV)\")\n",
    "ax.set_ylabel(\"a.u.\")\n",
    "plt.legend(loc=\"best\")\n",
    "ax.text(0.05,1.03,\"QCD jets\", transform=ax.transAxes)\n",
    "ax.text(0.45,1.03,loss_text, transform=ax.transAxes)\n",
    "plt.savefig(outdir+\"/sculptingQCD.png\")\n",
    "plt.show()\n",
    "print(cuts)\n",
    "\n",
    "plt.clf()\n",
    "fig, ax=plt.subplots()\n",
    "ax.hist2d(outputs[y_torch[:,1]==1][:,0].cpu().detach().numpy(),m_torch[y_torch[:,1]==1].cpu().detach().numpy(),bins=20)\n",
    "#ax.plot(m_torch.cpu().detach().numpy(),outputs[:,1].cpu().detach().numpy(),color=\"b\",label=\"Z'\")\n",
    "plt.legend(loc=\"best\")\n",
    "ax.set_ylabel(\"Jet mass (GeV)\")\n",
    "ax.set_xlabel(\"Discriminator\")\n",
    "ax.text(0.05,1.03,\"QCD jets\", transform=ax.transAxes)\n",
    "ax.text(0.45,1.03,loss_text, transform=ax.transAxes)\n",
    "plt.savefig(outdir+\"/discriminatorvsMassQCD.png\")\n",
    "plt.show()\n",
    "\n",
    "del y_torch, m_torch, outputs, outputs_optimal_clr\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d5a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f\"rm {outdir}/{label}_particleTrainingData.pt\")\n",
    "os.system(f\"rm {outdir}/{label}_jetMassTrainingData.pt\")\n",
    "os.system(f\"rm {outdir}/{label}_trainingLabels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6108ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
